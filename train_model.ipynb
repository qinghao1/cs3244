{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, random, sys, math, cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Model\n",
    "# from model import Model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aeschynanthus_parvifolius', 'bougainvillea_glabra', 'costus_woodsonii_maas', 'dillenia_excelsa', 'dillenia_indica', 'hedychium', 'hibiscus_rosa_sinensis', 'ixora_congesta', 'jasminum_sambac', 'lycoris', 'papilionanthe_miss_joaqium', 'plumeria']\n"
     ]
    }
   ],
   "source": [
    "# Read image categories\n",
    "ROOT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(ROOT_DIR, 'images')\n",
    "CATEGORIES = [folder for folder in os.listdir(IMAGE_DIR) \n",
    "               if os.path.isdir(os.path.join(IMAGE_DIR, folder))]\n",
    "CATEGORIES.sort() # Alphabetical order\n",
    "NUM_CLASSES = len(CATEGORIES)\n",
    "print(CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIM = (512, 512,)\n",
    "\n",
    "data_present = False\n",
    "\n",
    "if os.path.exists('data'):\n",
    "    x_train = np.load('data/train_images.npy')\n",
    "    y_train = np.load('data/train_labels.npy')\n",
    "    data_present = True\n",
    "    \n",
    "else:\n",
    "    # Read images and labels into arrays\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, category in enumerate(CATEGORIES):\n",
    "        print(\"Processing {} images...\".format(category))\n",
    "        folder_path = os.path.join(IMAGE_DIR, category)\n",
    "        # Read images in subfolder\n",
    "        for image_file_path in tqdm(glob.glob(folder_path + \"/*.jpg\")):\n",
    "            image_data = cv2.imread(image_file_path)\n",
    "            if image_data is None:\n",
    "                print(\"Faulty image {}; Ignoring...\".format(image_file_path))\n",
    "                continue\n",
    "            # Resize to constant dimensions\n",
    "            image_data = transform.resize(image_data, IMAGE_DIM)\n",
    "            images.append(image_data)\n",
    "            labels.append(label)\n",
    "\n",
    "    # Change labels to one-hot vector of length NUM_CLASSES instead of integers\n",
    "    labels = keras.utils.to_categorical(labels)\n",
    "\n",
    "    print(\"Read {} images and {} labels.\".format(len(images), len(labels))) # Should be same number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_present:\n",
    "    # Split into training and test sets\n",
    "    train_test_split_ratio = 0.9 # Proportion in train set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(images, labels, train_size = train_test_split_ratio)\n",
    "    print(\"{} training images, {} testing images\".format(len(x_train), len(x_test)))\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    x_train, x_test, y_train, y_test = np.array(x_train), np.array(x_test), np.array(y_train), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not data_present:\n",
    "    # Save arrays to file\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "    np.save('data/train_images', x_train)\n",
    "    np.save('data/train_labels', y_train)\n",
    "    np.save('data/test_images', x_test)\n",
    "    np.save('data/test_labels', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image data augmentation to increase effective dataset size\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255, # Rescale to range 0..1\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='wrap' # I.e. tiling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "base_model = keras.applications.densenet.DenseNet121(include_top=True, weights=None, input_shape=IMAGE_DIM+(3,), classes=NUM_CLASSES)\n",
    "model = keras.models.Model(inputs=base_model.input, outputs=base_model.get_layer(name='fc1000').output)\n",
    "model.compile(optimizer = keras.optimizers.Nadam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callback to save model weights\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint('weights.{epoch:02d}.h5', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights if they exist\n",
    "model.load_weights('weights.168.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.2542 - acc: 0.9133\n",
      "\n",
      "Epoch 00169: saving model to weights.169.h5\n",
      "Epoch 170/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2189 - acc: 0.9302\n",
      "\n",
      "Epoch 00176: saving model to weights.176.h5\n",
      "Epoch 177/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2833 - acc: 0.9020\n",
      "\n",
      "Epoch 00177: saving model to weights.177.h5\n",
      "Epoch 178/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2204 - acc: 0.9291\n",
      "\n",
      "Epoch 00178: saving model to weights.178.h5\n",
      "Epoch 179/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2920 - acc: 0.9009\n",
      "\n",
      "Epoch 00179: saving model to weights.179.h5\n",
      "Epoch 180/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2215 - acc: 0.9257\n",
      "\n",
      "Epoch 00180: saving model to weights.180.h5\n",
      "Epoch 181/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2832 - acc: 0.9133\n",
      "\n",
      "Epoch 00181: saving model to weights.181.h5\n",
      "Epoch 182/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2924 - acc: 0.8998\n",
      "\n",
      "Epoch 00182: saving model to weights.182.h5\n",
      "Epoch 183/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2887 - acc: 0.9155\n",
      "\n",
      "Epoch 00183: saving model to weights.183.h5\n",
      "Epoch 184/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2338 - acc: 0.9212\n",
      "\n",
      "Epoch 00184: saving model to weights.184.h5\n",
      "Epoch 185/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2302 - acc: 0.9392\n",
      "\n",
      "Epoch 00185: saving model to weights.185.h5\n",
      "Epoch 186/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2862 - acc: 0.9032\n",
      "\n",
      "Epoch 00186: saving model to weights.186.h5\n",
      "Epoch 187/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2026 - acc: 0.9257\n",
      "\n",
      "Epoch 00187: saving model to weights.187.h5\n",
      "Epoch 188/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1936 - acc: 0.9279\n",
      "\n",
      "Epoch 00188: saving model to weights.188.h5\n",
      "Epoch 189/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2349 - acc: 0.9234\n",
      "\n",
      "Epoch 00189: saving model to weights.189.h5\n",
      "Epoch 190/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2216 - acc: 0.9223\n",
      "\n",
      "Epoch 00196: saving model to weights.196.h5\n",
      "Epoch 197/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1782 - acc: 0.9347\n",
      "\n",
      "Epoch 00197: saving model to weights.197.h5\n",
      "Epoch 198/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1938 - acc: 0.9313\n",
      "\n",
      "Epoch 00198: saving model to weights.198.h5\n",
      "Epoch 199/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1778 - acc: 0.9459\n",
      "\n",
      "Epoch 00199: saving model to weights.199.h5\n",
      "Epoch 200/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1708 - acc: 0.9381\n",
      "\n",
      "Epoch 00200: saving model to weights.200.h5\n",
      "Epoch 201/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1588 - acc: 0.9426\n",
      "\n",
      "Epoch 00201: saving model to weights.201.h5\n",
      "Epoch 202/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1615 - acc: 0.9504\n",
      "\n",
      "Epoch 00202: saving model to weights.202.h5\n",
      "Epoch 203/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2061 - acc: 0.9392\n",
      "\n",
      "Epoch 00203: saving model to weights.203.h5\n",
      "Epoch 204/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.2312 - acc: 0.9245\n",
      "\n",
      "Epoch 00204: saving model to weights.204.h5\n",
      "Epoch 205/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1958 - acc: 0.9313\n",
      "\n",
      "Epoch 00205: saving model to weights.205.h5\n",
      "Epoch 206/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.2750 - acc: 0.9212\n",
      "\n",
      "Epoch 00206: saving model to weights.206.h5\n",
      "Epoch 207/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2286 - acc: 0.9347\n",
      "\n",
      "Epoch 00207: saving model to weights.207.h5\n",
      "Epoch 208/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1922 - acc: 0.9381\n",
      "\n",
      "Epoch 00214: saving model to weights.214.h5\n",
      "Epoch 215/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.1959 - acc: 0.9336\n",
      "\n",
      "Epoch 00215: saving model to weights.215.h5\n",
      "Epoch 216/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.2058 - acc: 0.9358\n",
      "\n",
      "Epoch 00216: saving model to weights.216.h5\n",
      "Epoch 217/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1997 - acc: 0.9246\n",
      "\n",
      "Epoch 00217: saving model to weights.217.h5\n",
      "Epoch 218/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1476 - acc: 0.9482\n",
      "\n",
      "Epoch 00218: saving model to weights.218.h5\n",
      "Epoch 219/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1842 - acc: 0.9370\n",
      "\n",
      "Epoch 00219: saving model to weights.219.h5\n",
      "Epoch 220/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.1966 - acc: 0.9313\n",
      "\n",
      "Epoch 00220: saving model to weights.220.h5\n",
      "Epoch 221/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1897 - acc: 0.9369\n",
      "\n",
      "Epoch 00221: saving model to weights.221.h5\n",
      "Epoch 222/300\n",
      "111/111 [==============================] - 163s 1s/step - loss: 0.1296 - acc: 0.9561\n",
      "\n",
      "Epoch 00222: saving model to weights.222.h5\n",
      "Epoch 223/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1370 - acc: 0.9583\n",
      "\n",
      "Epoch 00229: saving model to weights.229.h5\n",
      "Epoch 230/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1942 - acc: 0.9279\n",
      "\n",
      "Epoch 00230: saving model to weights.230.h5\n",
      "Epoch 231/300\n",
      "111/111 [==============================] - 167s 2s/step - loss: 0.1800 - acc: 0.9414\n",
      "\n",
      "Epoch 00231: saving model to weights.231.h5\n",
      "Epoch 232/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1502 - acc: 0.9493\n",
      "\n",
      "Epoch 00232: saving model to weights.232.h5\n",
      "Epoch 233/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1821 - acc: 0.9403\n",
      "\n",
      "Epoch 00233: saving model to weights.233.h5\n",
      "Epoch 234/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1578 - acc: 0.9426\n",
      "\n",
      "Epoch 00234: saving model to weights.234.h5\n",
      "Epoch 235/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1569 - acc: 0.9448\n",
      "\n",
      "Epoch 00235: saving model to weights.235.h5\n",
      "Epoch 236/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1615 - acc: 0.9403\n",
      "\n",
      "Epoch 00236: saving model to weights.236.h5\n",
      "Epoch 237/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.2138 - acc: 0.9403\n",
      "\n",
      "Epoch 00237: saving model to weights.237.h5\n",
      "Epoch 238/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.2262 - acc: 0.9223\n",
      "\n",
      "Epoch 00238: saving model to weights.238.h5\n",
      "Epoch 239/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.1356 - acc: 0.9504\n",
      "\n",
      "Epoch 00239: saving model to weights.239.h5\n",
      "Epoch 240/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1718 - acc: 0.9516\n",
      "\n",
      "Epoch 00240: saving model to weights.240.h5\n",
      "Epoch 241/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1825 - acc: 0.9392\n",
      "\n",
      "Epoch 00241: saving model to weights.241.h5\n",
      "Epoch 242/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.1175 - acc: 0.9628\n",
      "\n",
      "Epoch 00242: saving model to weights.242.h5\n",
      "Epoch 243/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1954 - acc: 0.9392\n",
      "\n",
      "Epoch 00243: saving model to weights.243.h5\n",
      "Epoch 244/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.2075 - acc: 0.9291\n",
      "\n",
      "Epoch 00244: saving model to weights.244.h5\n",
      "Epoch 245/300\n",
      "111/111 [==============================] - 167s 2s/step - loss: 0.2314 - acc: 0.9245\n",
      "\n",
      "Epoch 00245: saving model to weights.245.h5\n",
      "Epoch 246/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.1593 - acc: 0.9471\n",
      "\n",
      "Epoch 00246: saving model to weights.246.h5\n",
      "Epoch 247/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1735 - acc: 0.9448\n",
      "\n",
      "Epoch 00247: saving model to weights.247.h5\n",
      "Epoch 248/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1298 - acc: 0.9493\n",
      "\n",
      "Epoch 00248: saving model to weights.248.h5\n",
      "Epoch 249/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1551 - acc: 0.9460\n",
      "\n",
      "Epoch 00249: saving model to weights.249.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1545 - acc: 0.9403\n",
      "\n",
      "Epoch 00250: saving model to weights.250.h5\n",
      "Epoch 251/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1773 - acc: 0.9493\n",
      "\n",
      "Epoch 00251: saving model to weights.251.h5\n",
      "Epoch 252/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1559 - acc: 0.9493\n",
      "\n",
      "Epoch 00252: saving model to weights.252.h5\n",
      "Epoch 253/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1487 - acc: 0.9527\n",
      "\n",
      "Epoch 00253: saving model to weights.253.h5\n",
      "Epoch 254/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1275 - acc: 0.9516\n",
      "\n",
      "Epoch 00254: saving model to weights.254.h5\n",
      "Epoch 255/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1386 - acc: 0.9516\n",
      "\n",
      "Epoch 00255: saving model to weights.255.h5\n",
      "Epoch 256/300\n",
      " 12/111 [==>...........................] - ETA: 2:27 - loss: 0.1202 - acc: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 21/111 [====>.........................] - ETA: 2:15 - loss: 0.1279 - acc: 0.9583Epoch 284/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1251 - acc: 0.9595\n",
      "\n",
      "Epoch 00284: saving model to weights.284.h5\n",
      "Epoch 285/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1334 - acc: 0.9550\n",
      "\n",
      "Epoch 00285: saving model to weights.285.h5\n",
      "Epoch 286/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1852 - acc: 0.9448\n",
      "\n",
      "Epoch 00286: saving model to weights.286.h5\n",
      "Epoch 287/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1501 - acc: 0.9459\n",
      "\n",
      "Epoch 00287: saving model to weights.287.h5\n",
      "Epoch 288/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.2227 - acc: 0.9257\n",
      "\n",
      "Epoch 00288: saving model to weights.288.h5\n",
      "Epoch 289/300\n",
      "111/111 [==============================] - 166s 1s/step - loss: 0.1272 - acc: 0.9583\n",
      "\n",
      "Epoch 00289: saving model to weights.289.h5\n",
      "Epoch 290/300\n",
      "111/111 [==============================] - 164s 1s/step - loss: 0.0814 - acc: 0.9730\n",
      "\n",
      "Epoch 00290: saving model to weights.290.h5\n",
      "Epoch 291/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1054 - acc: 0.9651\n",
      "\n",
      "Epoch 00291: saving model to weights.291.h5\n",
      "Epoch 292/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.0925 - acc: 0.9673\n",
      "\n",
      "Epoch 00292: saving model to weights.292.h5\n",
      "Epoch 293/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1008 - acc: 0.9685\n",
      "\n",
      "Epoch 00293: saving model to weights.293.h5\n",
      "Epoch 294/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1384 - acc: 0.9505\n",
      "\n",
      "Epoch 00294: saving model to weights.294.h5\n",
      "Epoch 295/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1843 - acc: 0.9437\n",
      "\n",
      "Epoch 00295: saving model to weights.295.h5\n",
      "Epoch 296/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1526 - acc: 0.9550\n",
      "\n",
      "Epoch 00296: saving model to weights.296.h5\n",
      "Epoch 297/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1430 - acc: 0.9482\n",
      "\n",
      "Epoch 00297: saving model to weights.297.h5\n",
      "Epoch 298/300\n",
      "111/111 [==============================] - 165s 1s/step - loss: 0.1566 - acc: 0.9504\n",
      "\n",
      "Epoch 00298: saving model to weights.298.h5\n",
      "Epoch 299/300\n",
      "107/111 [===========================>..] - ETA: 5s - loss: 0.0995 - acc: 0.9720"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "# Hyper parameters\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 300\n",
    "STEPS_PER_EPOCH = len(x_train) // BATCH_SIZE\n",
    "\n",
    "model.fit_generator(\n",
    "    datagen.flow(x_train, y_train, batch_size = BATCH_SIZE),\n",
    "    steps_per_epoch = STEPS_PER_EPOCH,\n",
    "    epochs = EPOCHS,\n",
    "    callbacks = [model_checkpoint],\n",
    "    initial_epoch = 168\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
